{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWpMU50JH2M7"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAcHq4gdo3os"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.reload_library()\n",
    "\n",
    "from sktime.classification.interval_based import RandomIntervalSpectralEnsemble\n",
    "from sktime.classification.dictionary_based import ContractableBOSS, BOSSEnsemble \n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from wildboar.datasets import list_datasets\n",
    "from wildboar.datasets import load_dataset\n",
    "from wildboar.ensemble import ShapeletForestClassifier\n",
    "\n",
    "import pywt\n",
    "from pywt import wavedec, waverec\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SX2tjX_qE5lV"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCR_datasets = list_datasets(repository='wildboar/ucr')\n",
    "\n",
    "dataset_info = pd.DataFrame(columns=['size', 'classes', 'length'], index = UCR_datasets, dtype=float)\n",
    "\n",
    "for dataset in tqdm(UCR_datasets):\n",
    "    x_all, y_all = load_dataset(dataset, repository='wildboar/ucr')\n",
    "    \n",
    "    # remove rows wirandomth missing values\n",
    "    x = x_all[~np.isnan(x_all).any(axis=1)]\n",
    "    y = y_all[~np.isnan(x_all).any(axis=1)]\n",
    "    \n",
    "    classes = np.unique(y) # all class labels\n",
    "    total_examples, ts_length = x.shape\n",
    "    \n",
    "    dataset_info.loc[dataset] = [total_examples, len(classes), ts_length]\n",
    "    \n",
    "dataset_info.to_pickle('data/datasets_information.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select subset of all datasets\n",
    "dataset_info = pd.read_pickle('data/datasets_information.pkl')\n",
    "\n",
    "selected = dataset_info.loc[(dataset_info['size'] > 3) & \\\n",
    "                            (dataset_info['size'] < 1000) & \\\n",
    "                            (dataset_info['length'] > 20) & \\\n",
    "                            (dataset_info['length'] < 500)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_datasets = selected.index.to_list()\n",
    "\n",
    "classifiers = [\"kNN\",\"RSF\",\"Rocket\",\"RISE\",\"BOSS\",\"DFT\",\"DWT\"]\n",
    "\n",
    "splits = 5\n",
    "\n",
    "iterables = [selected_datasets, np.arange(splits)]\n",
    "m_index = pd.MultiIndex.from_product(iterables, names=[\"dataset\", \"split\"])\n",
    "\n",
    "accuracies = pd.DataFrame(columns=classifiers, index = m_index, dtype=float)\n",
    "complexity = pd.DataFrame(columns=classifiers, index = m_index, dtype=float)\n",
    "\n",
    "\n",
    "for dataset in tqdm(selected_datasets, desc = 'overall progress'):\n",
    "    x_all, y_all = load_dataset(dataset, repository='wildboar/ucr')\n",
    "    \n",
    "    # remove rows wirandomth missing values\n",
    "    x = x_all[~np.isnan(x_all).any(axis=1)]\n",
    "    y = y_all[~np.isnan(x_all).any(axis=1)]\n",
    "    \n",
    "    classes = np.unique(y) # all class labels\n",
    "    total_examples, ts_length = x.shape\n",
    "    \n",
    "    x_ind = np.arange(total_examples)\n",
    "    \n",
    "    max_len_coef_DFT = int(ts_length/2 + 1) # maximum number of DFT coefficients\n",
    "    max_len_coef_DWT = ts_length # maximum number of DWT coefficients\n",
    "\n",
    "\n",
    "    for i in tqdm(range(splits), desc = dataset, leave=False):\n",
    "        \n",
    "        # implement same split across all\n",
    "        \n",
    "        x_train_ind, x_test_ind, y_train, y_test = train_test_split(x_ind, y, test_size=.30, random_state=i, shuffle=True, stratify=None)\n",
    "        x_train2_ind, x_val_ind, y_train2, y_val = train_test_split(x_train_ind, y_train, test_size=.20, random_state=i, shuffle=True, stratify=None)\n",
    "\n",
    "\n",
    "        x_train = x[x_train_ind,:]\n",
    "        x_test = x[x_test_ind,:]\n",
    "    \n",
    "        np.random.seed(i)\n",
    "    \n",
    "    \n",
    "        ## kNN\n",
    "        if 'kNN' in classifiers:\n",
    "            \n",
    "            knn_time_start = time.time()\n",
    "            \n",
    "            f = KNeighborsClassifier(metric=\"euclidean\")\n",
    "            f.fit(x_train, y_train)\n",
    "            acc = f.score(x_test,y_test)\n",
    "            \n",
    "            knn_time_end = time.time()\n",
    "            \n",
    "            accuracies.loc[(dataset,i), \"kNN\"] = acc\n",
    "            complexity.loc[(dataset,i), \"kNN\"] = knn_time_end - knn_time_start\n",
    "        # ----------\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## RSF\n",
    "        if 'RSF' in classifiers:\n",
    "            rsf_time_start = time.time()\n",
    "            \n",
    "            f = ShapeletForestClassifier(n_estimators=50, metric='scaled_euclidean')\n",
    "            f.n_features_in_ = x_train.shape[-1]\n",
    "            f.fit(x_train, y_train)\n",
    "            acc = f.score(x_test,y_test)\n",
    "\n",
    "            rsf_time_end = time.time()\n",
    "            accuracies.loc[(dataset,i), \"RSF\"] = acc\n",
    "            complexity.loc[(dataset,i), \"RSF\"] = rsf_time_end - rsf_time_start\n",
    "            \n",
    "        # ----------\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        ## ROCKET\n",
    "        if 'Rocket' in classifiers:\n",
    "            \n",
    "            rocket_time_start = time.time()\n",
    "            \n",
    "            rocket = Rocket()  # by default, ROCKET uses 10,000 kernels\n",
    "            rocket.fit(x_train)\n",
    "\n",
    "            # transform training set and train classifier\n",
    "            x_training_transform = rocket.transform(x_train)\n",
    "\n",
    "            classifier = make_pipeline(StandardScaler(), RidgeClassifierCV(alphas = np.logspace(-3, 3, 10)))\n",
    "\n",
    "            classifier.fit(x_training_transform, y_train)\n",
    "\n",
    "            # transform test set and predict\n",
    "            x_test_transform = rocket.transform(x_test)\n",
    "            # predictions = classifier.predict(x_test_transform)\n",
    "            acc = classifier.score(x_test_transform,y_test)\n",
    "            \n",
    "            rocket_time_end = time.time()\n",
    "            \n",
    "            accuracies.loc[(dataset,i), \"Rocket\"] = acc\n",
    "            complexity.loc[(dataset,i), \"Rocket\"] = rocket_time_end - rocket_time_start\n",
    "        # -------------\n",
    "        \n",
    "        \n",
    "\n",
    "        ## RISE\n",
    "        if 'RISE' in classifiers:\n",
    "            rise_time_start = time.time()\n",
    "            classifierRISE = RandomIntervalSpectralEnsemble(random_state=i)\n",
    "\n",
    "            x_train_nested = from_2d_array_to_nested(x_train)\n",
    "            x_test_nested = from_2d_array_to_nested(x_test)\n",
    "        \n",
    "            classifierRISE.fit(x_train_nested, y_train)\n",
    "            # predictions = classifierRISE.predict(x_test_nested)\n",
    "            acc = classifierRISE.score(x_test_nested,y_test)\n",
    "            rise_time_end = time.time()\n",
    "            \n",
    "            accuracies.loc[(dataset,i), \"RISE\"] = acc\n",
    "            complexity.loc[(dataset,i), \"RISE\"] = rise_time_end - rise_time_start\n",
    "        # --------------\n",
    "        \n",
    "        \n",
    "        ## BOSS\n",
    "        if 'BOSS' in classifiers:\n",
    "            \n",
    "            boss_time_start = time.time()\n",
    "            classifierBOSS = BOSSEnsemble(random_state=i)\n",
    "            \n",
    "            x_train_nested = from_2d_array_to_nested(x_train)\n",
    "            x_test_nested = from_2d_array_to_nested(x_test)\n",
    "\n",
    "            classifierBOSS.fit(x_train_nested, y_train)\n",
    "            # predictions = classifierBOSS.predict(x_test_nested)\n",
    "            acc = classifierBOSS.score(x_test_nested,y_test)\n",
    "            boss_time_end = time.time()\n",
    "            \n",
    "            accuracies.loc[(dataset,i), \"BOSS\"] = acc\n",
    "            complexity.loc[(dataset,i), \"BOSS\"] = boss_time_end - boss_time_start\n",
    "        # --------------\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## DFT\n",
    "        if 'DFT' in classifiers:\n",
    "            \n",
    "            \n",
    "            dft_time_start = time.time()\n",
    "            \n",
    "            # Freq domain\n",
    "            X_F = np.fft.rfft(x)\n",
    "            \n",
    "            # combine amp and phase into one array\n",
    "            X_F_train = np.empty((x_train2_ind.shape[0],2*max_len_coef_DFT))\n",
    "            X_F_val = np.empty((x_val_ind.shape[0],2*max_len_coef_DFT))\n",
    "            X_F_test = np.empty((x_test.shape[0],2*max_len_coef_DFT))\n",
    "\n",
    "            X_F_train[:,0::2] = normalize(np.absolute(X_F[x_train2_ind,:]), axis=1)  # amplitude\n",
    "            X_F_train[:,1::2] = normalize(np.angle(X_F[x_train2_ind,:]), axis=1)     # phase\n",
    "            X_F_val[:,0::2] = normalize(np.absolute(X_F[x_val_ind,:]), axis=1)  # amplitude\n",
    "            X_F_val[:,1::2] = normalize(np.angle(X_F[x_val_ind,:]), axis=1)     # phase\n",
    "            X_F_test[:,0::2] = normalize(np.absolute(X_F[x_test_ind,:]), axis=1)  # amplitude\n",
    "            X_F_test[:,1::2] = normalize(np.angle(X_F[x_test_ind,:]), axis=1)     # phase\n",
    "            \n",
    "            fracs = [.1,.25,.5,.75,1]\n",
    "            acc_val = np.empty(len(fracs))\n",
    "            acc_test = np.empty(len(fracs))\n",
    "            \n",
    "            for idx, L_DFT_frac in enumerate(fracs):\n",
    "\n",
    "                L_DFT = int(L_DFT_frac*max_len_coef_DFT)\n",
    "                clf = ExtraTreesClassifier(random_state=1)\n",
    "                clf.fit(X_F_train[:,:2*L_DFT], y_train2)\n",
    "                acc_val[idx] = clf.score(X_F_val[:,:2*L_DFT], y_val)\n",
    "                acc_test[idx] = clf.score(X_F_test[:,:2*L_DFT], y_test)\n",
    "            \n",
    "            dft_time_end = time.time()\n",
    "\n",
    "            accuracies.loc[(dataset,i), \"DFT\"] = acc_test[np.argmax(acc_val)]\n",
    "            complexity.loc[(dataset,i), \"DFT\"] = dft_time_end - dft_time_start\n",
    "            \n",
    "        # --------------\n",
    "\n",
    "        \n",
    "        if 'DWT' in classifiers:\n",
    "            \n",
    "            dwt_time_start = time.time()\n",
    "            \n",
    "            # Time-Freq domain\n",
    "            level=3 # no of DWT decomposition levels \n",
    "            waveletname='db2'\n",
    "            \n",
    "            X_TF = wavedec(x, waveletname, level=level) ## If using DWT\n",
    "            X_TF_stacked = np.hstack(X_TF)\n",
    "        \n",
    "            X_TF_train = X_TF_stacked[x_train2_ind,:]\n",
    "            X_TF_val = X_TF_stacked[x_val_ind,:]\n",
    "            X_TF_test = X_TF_stacked[x_test_ind,:]\n",
    "            \n",
    "            fracs = [.1,.25,.5,.75,.1]\n",
    "            acc_val = np.empty(len(fracs))\n",
    "            acc_test = np.empty(len(fracs))\n",
    "            for idx, L_DWT_frac in enumerate(fracs):\n",
    "            \n",
    "                L_DWT = int(L_DWT_frac*max_len_coef_DWT)\n",
    "                clf = ExtraTreesClassifier(random_state=1)\n",
    "                \n",
    "                clf.fit(X_TF_train[:,:L_DWT], y_train2)\n",
    "                acc_val[idx] = clf.score(X_TF_val[:,:L_DWT], y_val)\n",
    "                acc_test[idx] = clf.score(X_TF_test[:,:L_DWT], y_test)\n",
    "            \n",
    "            dwt_time_end = time.time()\n",
    "            \n",
    "            accuracies.loc[(dataset,i), \"DWT\"] = acc_test[np.argmax(acc_val)]\n",
    "            complexity.loc[(dataset,i), \"DWT\"] = dwt_time_end - dwt_time_start\n",
    "        # --------------\n",
    "        \n",
    "        # save results\n",
    "        accuracies.to_pickle('data/accuracies_new.pkl')\n",
    "        complexity.to_pickle('data/complexity_new.pkl')\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rWpMU50JH2M7",
    "qjVC9cgPIGlg"
   ],
   "name": "SPM TSexplainability.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1fbce0ce74484155928d19e86e0d8e68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bd4713048d94d3b902b84368a079b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fbce0ce74484155928d19e86e0d8e68",
      "max": 60,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7bba8b218894aa8b2a0c276a06ac31c",
      "value": 60
     }
    },
    "4679b4191200432ba1d8ec48e42bd2ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b3c81e73df2486fabe2ec2566b19d79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0cb1f7d25db4f2d89bad1cd5afc3a0f",
      "placeholder": "​",
      "style": "IPY_MODEL_fee2649187c243ad968fbc3d53f84420",
      "value": " 60/60 [01:32&lt;00:00,  1.54s/it]"
     }
    },
    "b0cb1f7d25db4f2d89bad1cd5afc3a0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7bba8b218894aa8b2a0c276a06ac31c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "de306d595a194bfb9233307a63560793": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bd4713048d94d3b902b84368a079b0f",
       "IPY_MODEL_9b3c81e73df2486fabe2ec2566b19d79"
      ],
      "layout": "IPY_MODEL_4679b4191200432ba1d8ec48e42bd2ce"
     }
    },
    "fee2649187c243ad968fbc3d53f84420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
